{
	"name": "dataflowhospitaladmission",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "dataflowdatset2",
						"type": "DatasetReference"
					},
					"name": "source1"
				},
				{
					"dataset": {
						"referenceName": "lookupdataset",
						"type": "DatasetReference"
					},
					"name": "lookupdataset"
				},
				{
					"dataset": {
						"referenceName": "DelimitedText1",
						"type": "DatasetReference"
					},
					"name": "dimdataset"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "daily_output_hospital_data",
						"type": "DatasetReference"
					},
					"name": "sink1"
				},
				{
					"dataset": {
						"referenceName": "DelimitedText2",
						"type": "DatasetReference"
					},
					"name": "sink2"
				}
			],
			"transformations": [
				{
					"name": "select1"
				},
				{
					"name": "lookup1"
				},
				{
					"name": "select2"
				},
				{
					"name": "split1"
				},
				{
					"name": "aggregate1"
				},
				{
					"name": "join1"
				},
				{
					"name": "pivot1"
				},
				{
					"name": "pivot2"
				}
			],
			"scriptLines": [
				"source(output(",
				"          country as string,",
				"          indicator as string,",
				"          date as date,",
				"          year_week as string,",
				"          value as double,",
				"          source as string,",
				"          url as string",
				"     ),",
				"     allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     limit: 1009,",
				"     ignoreNoFilesFound: false) ~> source1",
				"source(output(",
				"          country as string,",
				"          country_code_2_digit as string,",
				"          country_code_3_digit as string,",
				"          continent as string,",
				"          population as integer",
				"     ),",
				"     allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     ignoreNoFilesFound: false) ~> lookupdataset",
				"source(output(",
				"          date_key as string,",
				"          date as string,",
				"          year as string,",
				"          month as string,",
				"          day as string,",
				"          day_name as string,",
				"          day_of_year as string,",
				"          week_of_month as string,",
				"          week_of_year as string,",
				"          month_name as string,",
				"          year_month as string,",
				"          year_week as string",
				"     ),",
				"     allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     ignoreNoFilesFound: false) ~> dimdataset",
				"source1 select(mapColumn(",
				"          country,",
				"          indicator,",
				"          reported_date = date,",
				"          reported_year_week = year_week,",
				"          value,",
				"          source",
				"     ),",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true) ~> select1",
				"select1, lookupdataset lookup(select1@country == lookupdataset@country,",
				"     multiple: false,",
				"     pickup: 'any',",
				"     broadcast: 'auto')~> lookup1",
				"lookup1 select(mapColumn(",
				"          country = select1@country,",
				"          indicator,",
				"          reported_date,",
				"          reported_year_week,",
				"          value,",
				"          source,",
				"          country = lookupdataset@country,",
				"          country_code_2_digit,",
				"          country_code_3_digit,",
				"          population",
				"     ),",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true) ~> select2",
				"select2 split(indicator == 'Weekly new hospital admissions per 100k' || indicator == 'Weekly new ICU admissions per 100k',",
				"     disjoint: false) ~> split1@(weeklydata, daily)",
				"dimdataset aggregate(groupBy(ecdc_year_week = year + '-w' + lpad(week_of_year, 2 , '0')),",
				"     week_start_date = min(date),",
				"          week_end_date = max(date)) ~> aggregate1",
				"split1@weeklydata, aggregate1 join(reported_year_week == ecdc_year_week,",
				"     joinType:'inner',",
				"     matchType:'exact',",
				"     ignoreSpaces: false,",
				"     broadcast: 'auto')~> join1",
				"join1 pivot(groupBy(country,",
				"          reported_year_week,",
				"          reported_date,",
				"          value,",
				"          country_code_2_digit,",
				"          population,",
				"          ecdc_year_week,",
				"          week_start_date,",
				"          week_end_date),",
				"     pivotBy(indicator, ['Weekly new ICU admissions per 100k', 'Weekly new hospital admissions per 100k']),",
				"     count = sum(value),",
				"     columnNaming: '$N$V',",
				"     lateral: true) ~> pivot1",
				"split1@daily pivot(groupBy(country,",
				"          reported_date,",
				"          reported_year_week,",
				"          value,",
				"          source,",
				"          country_code_3_digit,",
				"          population),",
				"     pivotBy(indicator, ['Daily hospital occupancy', 'Daily ICU occupancy']),",
				"     count = sum(value),",
				"     columnNaming: '$N$V',",
				"     lateral: false) ~> pivot2",
				"pivot2 sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     partitionFileNames:['daily_data.csv'],",
				"     umask: 0022,",
				"     preCommands: [],",
				"     postCommands: [],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     partitionBy('hash', 1)) ~> sink1",
				"pivot1 sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     input(",
				"          country as string,",
				"          country_code as string,",
				"          continent as string,",
				"          population as string,",
				"          indicator as string,",
				"          daily_count as string,",
				"          date as string,",
				"          rate_14_day as string,",
				"          source as string",
				"     ),",
				"     partitionFileNames:['weekly_output.csv'],",
				"     umask: 0022,",
				"     preCommands: [],",
				"     postCommands: [],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     partitionBy('hash', 1)) ~> sink2"
			]
		}
	}
}